[optimizer]
optimizer = adam
learning_rate = 0.001
momentum = 0.9
betas = 0.9, 0.999
epsilon = 1e-8
weight_decay = 0

[training]
loss = mse
batch_size_train = 128
batch_size_test = 128
epochs = 50

[segmentation]
sigma = 0.5
scale = 750
min_size = 80
min_reco = 1000

[smoothing]
kernel = 31
stride = 1
padding = 15